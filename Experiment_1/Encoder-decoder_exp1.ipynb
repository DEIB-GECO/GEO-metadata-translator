{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1585669275140,
     "user": {
      "displayName": "Giuseppe Cannizzaro",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh2rwxXOtNd1FXyx9Hy22uSBPNBSANIiogcvrnB-w=s64",
      "userId": "07112207170858818112"
     },
     "user_tz": -120
    },
    "id": "BH87mO1gIWV1",
    "outputId": "0adfb3a7-4a37-4a57-a896-a1fc840efca9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-rc1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1099,
     "status": "ok",
     "timestamp": 1584801469275,
     "user": {
      "displayName": "Giuseppe Cannizzaro",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh2rwxXOtNd1FXyx9Hy22uSBPNBSANIiogcvrnB-w=s64",
      "userId": "07112207170858818112"
     },
     "user_tz": -60
    },
    "id": "FT7T-i-Hu9CS",
    "outputId": "dd2a158c-1eac-4f63-a715-70125da60d47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rav3zMCilAwO"
   },
   "outputs": [],
   "source": [
    "SAVE = True\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "LSTM_SIZE = 512\n",
    "EMBEDDING_SIZE = 256\n",
    "SPLIT = 0.9\n",
    "FILENAME = \"Experiment_1/Data/CISTROME_no_protocol.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-5MLqHQ5lJv1"
   },
   "outputs": [],
   "source": [
    "frame = pd.read_csv(FILENAME)\n",
    "train_frame, test_frame = train_test_split(frame, train_size = SPLIT)\n",
    "train_frame, val_frame = train_test_split(train_frame, train_size = SPLIT)\n",
    "val = [[x.replace(\"(\",\" ( \").replace(\")\", \" ) \").replace(\"-\",' - ').replace(\"_\",\" _ \").replace(\";\",\" ; \").replace(\"  \",\" \").replace(\"=\",\"\"),'<start> ' + y.replace(\" $\",\"\"), y.replace(\" $\",\"\") + ' <end>'] for (x,y) in zip(val_frame.Input, val_frame.Output)]\n",
    "train = [[x.replace(\"(\",\" ( \").replace(\")\", \" ) \").replace(\"-\",' - ').replace(\"_\",\" _ \").replace(\";\",\" ; \").replace(\"  \",\" \").replace(\"=\",\"\"),'<start> ' + y.replace(\" $\",\"\"), y.replace(\" $\",\"\") + ' <end>'] for (x,y) in zip(train_frame.Input, train_frame.Output)]\n",
    "test = [[x.replace(\"(\",\" ( \").replace(\")\", \" ) \").replace(\"-\",' - ').replace(\"_\",\" _ \").replace(\";\",\" ; \").replace(\"  \",\" \").replace(\"=\",\"\"),'<start> ' + y.replace(\" $\",\"\"), y.replace(\" $\",\"\") + ' <end>'] for (x,y) in zip(test_frame.Input, test_frame.Output)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8l2nmQLMolPI"
   },
   "outputs": [],
   "source": [
    "def tokenize_dataset(train, test, val, differentiate_vocabularies = False):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', lower=True, split=' ', char_level=False)\n",
    "    for index in range(3):\n",
    "        tokenizer.fit_on_texts(x[index] for x in train)\n",
    "        tokenizer.fit_on_texts(x[index] for x in test)\n",
    "        tokenizer.fit_on_texts(x[index] for x in val)\n",
    "        \n",
    "    train_in = tokenizer.texts_to_sequences(i[0] for i in train)\n",
    "    train_in = tf.keras.preprocessing.sequence.pad_sequences(train_in, padding='post')\n",
    "    train_outi = tokenizer.texts_to_sequences(i[1] for i in train)\n",
    "    train_outi = tf.keras.preprocessing.sequence.pad_sequences(train_outi, padding='post')\n",
    "    train_outo = tokenizer.texts_to_sequences(i[2] for i in train)\n",
    "    train_outo = tf.keras.preprocessing.sequence.pad_sequences(train_outo, padding='post')\n",
    "\n",
    "    test_in = tokenizer.texts_to_sequences(i[0] for i in test)\n",
    "    test_in = tf.keras.preprocessing.sequence.pad_sequences(test_in, padding='post')\n",
    "    test_outi = tokenizer.texts_to_sequences(i[1] for i in test)\n",
    "    test_outi = tf.keras.preprocessing.sequence.pad_sequences(test_outi, padding='post')\n",
    "    test_outo = tokenizer.texts_to_sequences(i[2] for i in test)\n",
    "    test_outo = tf.keras.preprocessing.sequence.pad_sequences(test_outo, padding='post')\n",
    "    \n",
    "    val_in = tokenizer.texts_to_sequences(i[0] for i in val)\n",
    "    val_in = tf.keras.preprocessing.sequence.pad_sequences(val_in, padding='post')\n",
    "    val_outi = tokenizer.texts_to_sequences(i[1] for i in val)\n",
    "    val_outi = tf.keras.preprocessing.sequence.pad_sequences(val_outi, padding='post')\n",
    "    val_outo = tokenizer.texts_to_sequences(i[2] for i in val)\n",
    "    val_outo = tf.keras.preprocessing.sequence.pad_sequences(val_outo, padding='post')\n",
    "\n",
    "\n",
    "    return tokenizer,train_in, train_outi, train_outo, test_in, test_outi, test_outo, val_in, val_outi, val_outo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06FU_sR9o9bQ"
   },
   "outputs": [],
   "source": [
    "tokenizer, train_in, train_outi, train_outo,\n",
    "test_in, test_outi, test_outo,\n",
    "val_in, val_outi, val_outo = tokenize_dataset(train,test,val)\n",
    "\n",
    "training_set = tf.data.Dataset.from_tensor_slices((train_in,train_outi, train_outo))\n",
    "training_set = training_set.shuffle(20).batch(BATCH_SIZE)\n",
    "\n",
    "test_set = tf.data.Dataset.from_tensor_slices((test_in, test_outi, test_outo))\n",
    "test_set = test_set.shuffle(20).batch(BATCH_SIZE)\n",
    "\n",
    "val_set = tf.data.Dataset.from_tensor_slices((val_in, val_outi, val_outo))\n",
    "val_set = val_set.shuffle(20).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kd46QBY0p6_b"
   },
   "outputs": [],
   "source": [
    "class LuongAttention(tf.keras.Model):\n",
    "    def __init__(self, rnn_size):\n",
    "        super(LuongAttention, self).__init__()\n",
    "        self.wa = tf.keras.layers.Dense(rnn_size)\n",
    "        \n",
    "    def call(self, decoder_output, encoder_output):\n",
    "        # Dot score: h_t (dot) Wa (dot) h_s\n",
    "        # encoder_output shape: (batch_size, max_len, rnn_size)\n",
    "        # decoder_output shape: (batch_size, 1, rnn_size)\n",
    "        # score will have shape: (batch_size, 1, max_len)\n",
    "        score = tf.matmul(decoder_output, self.wa(encoder_output), transpose_b=True)\n",
    "        # alignment vector a_t\n",
    "        alignment = tf.nn.softmax(score, axis=2)\n",
    "        context = tf.matmul(alignment, encoder_output)\n",
    "\n",
    "        return context, alignment\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, lstm_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = tf.keras.layers.LSTM(\n",
    "            lstm_size, return_sequences=True, return_state=True)\n",
    "\n",
    "    def call(self, sequence, states):\n",
    "        embed = self.embedding(sequence)\n",
    "        output, state_h, state_c = self.lstm(embed, initial_state=states)\n",
    "\n",
    "        return output, state_h, state_c\n",
    "\n",
    "    def init_states(self, batch_size):\n",
    "        return (tf.zeros([batch_size, self.lstm_size]),\n",
    "                tf.zeros([batch_size, self.lstm_size]))\n",
    "\n",
    "#DECODER FOR ATTENTION\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, rnn_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # Create a LuongAttention object\n",
    "        self.attention = LuongAttention(rnn_size)\n",
    "\n",
    "        self.rnn_size = rnn_size\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = tf.keras.layers.LSTM(\n",
    "            rnn_size, return_sequences=True, return_state=True)\n",
    "        self.wc = tf.keras.layers.Dense(rnn_size, activation='tanh')\n",
    "        self.ws = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, sequence, state, encoder_output):\n",
    "        # Remember that the input to the decoder\n",
    "        # is now a batch of one-word sequences,\n",
    "        # which means that its shape is (batch_size, 1)\n",
    "        embed = self.embedding(sequence)\n",
    "        \n",
    "        # Therefore, the lstm_out has shape (batch_size, 1, rnn_size)\n",
    "        lstm_out, state_h, state_c = self.lstm(embed, initial_state=state)\n",
    "        # Use self.attention to compute the context and alignment vectors\n",
    "        # context vector's shape: (batch_size, 1, rnn_size)\n",
    "        # alignment vector's shape: (batch_size, 1, source_length)\n",
    "        context, alignment = self.attention(lstm_out, encoder_output)\n",
    "        # Combine the context vector and the LSTM output\n",
    "        # Before combined, both have shape of (batch_size, 1, rnn_size),\n",
    "        # so let's squeeze the axis 1 first\n",
    "        # After combined, it will have shape of (batch_size, 2 * rnn_size)\n",
    "        lstm_out = tf.concat([tf.squeeze(context, 1), tf.squeeze(lstm_out, 1)], 1)\n",
    "        \n",
    "        # lstm_out now has shape (batch_size, rnn_size)\n",
    "        lstm_out = self.wc(lstm_out)\n",
    "        \n",
    "        # Finally, it is converted back to vocabulary space: (batch_size, vocab_size)\n",
    "        logits = self.ws(lstm_out)\n",
    "\n",
    "        return logits, state_h, state_c, alignment\n",
    "\n",
    "def loss_func(targets, logits):\n",
    "    crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True)\n",
    "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
    "    mask = tf.cast(mask, dtype=tf.int64)\n",
    "    loss = crossentropy(targets, logits, sample_weight=mask)\n",
    "\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zoOQaNd_qMho"
   },
   "outputs": [],
   "source": [
    "#TRAIN FOR ATTENTION\n",
    "@tf.function\n",
    "def train_step(source_seq, target_seq_in, target_seq_out, en_initial_states):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        en_outputs = encoder(source_seq, en_initial_states)\n",
    "        en_states = en_outputs[1:]\n",
    "        de_state_h, de_state_c = en_states\n",
    "        \n",
    "        # We need to create a loop to iterate through the target sequences\n",
    "        for i in range(target_seq_out.shape[1]):\n",
    "            # Input to the decoder must have shape of (batch_size, length)\n",
    "            # so we need to expand one dimension\n",
    "            decoder_in = tf.expand_dims(target_seq_in[:, i], 1)\n",
    "            logit, de_state_h, de_state_c, _ = decoder(decoder_in, (de_state_h, de_state_c), en_outputs[0])\n",
    "            \n",
    "            # The loss is now accumulated through the whole batch\n",
    "            loss += loss_func(target_seq_out[:, i], logit)\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return loss / target_seq_out.shape[1]\n",
    "    \n",
    "#TEST FOR ATTENTION\n",
    "@tf.function\n",
    "def test_step(source_seq, target_seq_in, target_seq_out, en_initial_states):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        en_outputs = encoder(source_seq, en_initial_states)\n",
    "        en_states = en_outputs[1:]\n",
    "        de_state_h, de_state_c = en_states\n",
    "        \n",
    "        # We need to create a loop to iterate through the target sequences\n",
    "        for i in range(target_seq_out.shape[1]):\n",
    "            # Input to the decoder must have shape of (batch_size, length)\n",
    "            # so we need to expand one dimension\n",
    "            decoder_in = tf.expand_dims(target_seq_in[:, i], 1)\n",
    "            logit, de_state_h, de_state_c, _ = decoder(\n",
    "                decoder_in, (de_state_h, de_state_c), en_outputs[0])\n",
    "            \n",
    "            # The loss is now accumulated through the whole batch\n",
    "            loss += loss_func(target_seq_out[:, i], logit)\n",
    "\n",
    "    return loss / target_seq_out.shape[1]\n",
    "\n",
    "#PREDICT FOR ATTENTION\n",
    "def predict(test_source_text=None):\n",
    "    choice = np.random.choice(len(test))\n",
    "    if test_source_text is None:\n",
    "        test_source_text = test[choice][0]\n",
    "        target_text = test[choice][2].split(\" \")\n",
    "    print(test_source_text)\n",
    "    print(\"TARGET\")\n",
    "    print(' '.join(target_text))   \n",
    "    test_source_seq = tokenizer.texts_to_sequences([test_source_text])\n",
    "\n",
    "    en_initial_states = encoder.init_states(1)\n",
    "    en_outputs = encoder(tf.constant(test_source_seq), en_initial_states)\n",
    "\n",
    "    de_input = tf.constant([[tokenizer.word_index['<start>']]])\n",
    "    de_state_h, de_state_c = en_outputs[1:]\n",
    "    out_words = []\n",
    "    alignments = []\n",
    "\n",
    "    while True:\n",
    "        de_output, de_state_h, de_state_c, alignment = decoder(\n",
    "            de_input, (de_state_h, de_state_c), en_outputs[0])\n",
    "        de_input = tf.expand_dims(tf.argmax(de_output, -1), 0)\n",
    "        \n",
    "        out_words.append(tokenizer.index_word[de_input.numpy()[0][0]])\n",
    "        alignments.append(alignment.numpy())     \n",
    "        if out_words[-1] == '<end>' or len(out_words) >= 100:\n",
    "            break\n",
    "        \n",
    "    print(\"PREDICTED\")\n",
    "    print(' '.join(out_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3053284,
     "status": "ok",
     "timestamp": 1584806365802,
     "user": {
      "displayName": "Giuseppe Cannizzaro",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh2rwxXOtNd1FXyx9Hy22uSBPNBSANIiogcvrnB-w=s64",
      "userId": "07112207170858818112"
     },
     "user_tz": -60
    },
    "id": "D7ojcnZqqXnH",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3255f52e-aebf-4f97-dcad-ee1da00582a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete, now testing...\n",
      "Epoch 1 Training Loss 1.8006, Test Loss 0.8440\n",
      "Title: 24h - diff - WT _ H3K27me1 _ rep1 - Description: developmental stage: 24 hours differentiated ES cells ; chip antibody: H3K27me1 ( Millipore, 07 - 448, lot unknown ) ; strain: E14 - Characteristics: Mus musculus\n",
      "TARGET\n",
      "Cell Line: None - Cell Type: Embryonic Stem Cell - Tissue Type: None - Factor: H3K27me1 <end>\n",
      "PREDICTED\n",
      "cell line: none - tissue type: none - factor: h3k4me3 <end>\n",
      "Training complete, now testing...\n",
      "Epoch 2 Training Loss 0.7432, Test Loss 0.7002\n",
      "Title: Broad _ ChipSeq _ A549 _ H3K36me3 _ DEX _ 100nM - Description: datatype: ChipSeq ; datatype description: Chromatin IP Sequencing ; antibody antibodydescription: rabbit polyclonal. Antibody Target: H3K36me3 ; antibody targetdescription: Specific for histone H3 tri methylated at lysine 36, weakly reacts with H3K36me2. Marks regions of RNAPII elongation, including coding and non - coding transcripts. ; antibody vendorname: abcam ; antibody vendorid: ab9050 ; controlid: wgEncodeEH003075 ; replicate: 1,2 ; softwareversion: ScriptureVPaperR3 ; cell sex: M ; antibody: H3K36me3 ; antibody antibodydescription: rabbit polyclonal. Antibody Target: H3K36me3 ; antibody targetdescription: Histone H3 ( tri - methyl K36 ) . Marks regions of RNAPII elongation, including coding and non - coding transcripts. ; antibody vendorname: Abcam ; antibody vendorid: ab9050 ; treatment: DEX _ 100nM ; treatment description: 1 h with 100 nM Dexamethasone ( Myers ) ; control: std ; control description: Standard input signal for most experiments. ; controlid: A549/DEX _ 100nM/Input/std ; labversion: Illumina _ HiSeq _ 2000 ; labversion description: Illumina HiSeq 2000 ; softwareversion: ScriptureVPaperR3 - Characteristics: Homo sapiens\n",
      "TARGET\n",
      "Cell Line: A549 - Cell Type: Epithelium - Tissue Type: Lung - Factor: H3K36me3 <end>\n",
      "PREDICTED\n",
      "cell line: none - cell type: none - tissue type: none - factor: h3k4me3 <end>\n",
      "Training complete, now testing...\n",
      "Epoch 3 Training Loss 0.6707, Test Loss 0.6531\n",
      "Title: SCC4KO CTCF ChIPseq - Description: CRISPRs targeting WAPL ( 5’ - CACCGCGTTCCATAGTATCCTGTA - 3’ ) and SCC4 ( 5’ - CACCGTACGGGCCTCGATGCGCTG - 3’ ) were cloned into px330 ( Addgene plasmid #42230 ) . ∆WAPL and ∆SCC4 HAP1 clones were generated by insertion of a Blasticidine or Puromycin cassette respectively, as previously described ( Blomen et al., 2015 ) . ∆WAPL/∆SCC4 cells were generated by knocking out SCC4 in ∆WAPL cells. - Characteristics: cell line: Hap1 ; genotype/variation: SCC4KO ; antibody: CTCF\n",
      "TARGET\n",
      "Cell Line: HAP-1 - Cell Type: Embryonic Stem Cell - Tissue Type: Embryo - Factor: CTCF <end>\n",
      "PREDICTED\n",
      "cell line: none - cell type: epithelium - tissue type: liver - factor: polr2a <end>\n",
      "Training complete, now testing...\n",
      "Epoch 4 Training Loss 0.6211, Test Loss 0.5578\n",
      "Title: BulkCTCL _ Patient5 _ Vori _ Day7 - Description: For patients diagnosed with CTCL were treated with either Vorinostat of Romidepsin, based on their clinical tests. - Characteristics: subject status: patiet with cutaneous T cell leukemia ( CTCL ) ; subject gender: Male ; cell type: human CD4+ T cell ; cell subtype: Bulk Cells\n",
      "TARGET\n",
      "Cell Line: None - Cell Type: T Lymphocyte - Tissue Type: None - Factor: ATAC-seq <end>\n",
      "PREDICTED\n",
      "cell line: none - cell type: embryonic stem cell - tissue type: none - factor: h3k4me3 <end>\n",
      "Training complete, now testing...\n",
      "Epoch 5 Training Loss 0.4783, Test Loss 0.4401\n",
      "Title: H3K4me2 in differentated cells - Description: cell type: human intestinal cell line ; cell line: Caco - 2 ; chip antibody: H3K4me2 ( Millipore 07 - 030 )  - Characteristics: Homo sapiens\n",
      "TARGET\n",
      "Cell Line: Caco-2 - Cell Type: Epithelium - Tissue Type: Colon - Factor: H3K4me2 <end>\n",
      "PREDICTED\n",
      "cell line: none - cell type: t lymphocyte - tissue type: blood - factor: dnase <end>\n",
      "Training complete, now testing...\n",
      "Epoch 6 Training Loss 0.3880, Test Loss 0.3814\n",
      "Title: BG _ d6 _ H3K9me3 - Description: background strain: Adult Human Peripheral Blood ; cell type: Monocyte ; treatment: BG - Mf ( BG exposed 24 hours, culture for 5 days to macrophage ) ; chip antibody: Rabbit polyclonal anti - H3K9me3 ( Diagenode, cat. # pAb - 193 - 050 )  - Characteristics: Homo sapiens\n",
      "TARGET\n",
      "Cell Line: None - Cell Type: Monocyte - Tissue Type: Blood - Factor: H3K9me3 <end>\n",
      "PREDICTED\n",
      "cell line: none - cell type: embryonic stem cell - tissue type: embryo - factor: h3 <end>\n",
      "Training complete, now testing...\n",
      "Epoch 7 Training Loss 0.3244, Test Loss 0.3340\n",
      "Title: XBP1 - ChIPseq Liver SHAM6h - Description: strain: C57Bl6 - J ; tissue: liver ; genotype: wildtype ; chip antibody: anti - XBP1 M - 186 ( sc - 7160 - X, Santa Cruz, Heidelberg, Germany )  - Characteristics: Mus musculus\n",
      "TARGET\n",
      "Cell Line: None - Cell Type: None - Tissue Type: Liver - Factor: XBP1 <end>\n",
      "PREDICTED\n",
      "cell line: none - cell type: embryonic stem cell - tissue type: embryo - factor: polr2a <end>\n",
      "Training complete, now testing...\n",
      "Epoch 8 Training Loss 0.2716, Test Loss 0.2985\n",
      "Title: Pmel - shGFP - H3K79ME1 - Description: partially transformed melanocytic line: PMEL ; clone subtype: Pmel - shGFP ; cell phentype: non - tumorigenic variant ; chip antibody: H3K79ME1 ; chip antibody vendor - cat.#: Abcam - ab2886 - Characteristics: Homo sapiens\n",
      "TARGET\n",
      "Cell Line: None - Cell Type: Melanocytic cell - Tissue Type: None - Factor: H3K79me1 <end>\n",
      "PREDICTED\n",
      "cell line: none - cell type: melanocytic cell - tissue type: none - factor: h3k4me2 <end>\n",
      "Training complete, now testing...\n",
      "Epoch 9 Training Loss 0.2281, Test Loss 0.2675\n",
      "Title: Reference Epigenome: ChIP - Seq Analysis of H2BK5ac in Mesenchymal Stem Cells ; renlab.H2BK5ac.MSC.01.01 - Description: sample alias: MSC - 01 ; sample common name: H1 Derived Mesenchymal Stem Cells ; molecule: genomic DNA ; disease: None ; biomaterial _ provider: James Thomson Laboratory ; biomaterial _ type: Cell Line ; line: H1 ; lineage: Embryonic Stem Cell ; differentiation _ stage: Embryonic stem cell differentiated into mesenchymal stem cells ; differentiation _ method: Publication in progress ; passage: 6 ; medium: Publication in progress ; Sex: Male ; batch: MSC - 1 ; experiment _ type: Histone H2BK5ac ; extraction _ protocol: See http://bioinformatics - renlab.ucsd.edu/RenLabChipProtocolV1.pdf ; extraction _ protocol _ type _ of _ sonicator: Biorupter ; extraction _ protocol _ sonication _ cycles: 80 ; chip _ protocol: See http://bioinformatics - renlab.ucsd.edu/RenLabChipProtocolV1.pdf ; chip _ protocol _ chromatin _ amount: 500 micrograms ; chip _ protocol _ bead _ type: magnetic anti - rabbit ; chip _ protocol _ bead _ amount: 33,500,000 ; chip _ protocol _ antibody _ amount: 5 micrograms ; chip _ antibody: H2BK5ac ; chip _ antibody _ provider: Active Motif ; chip _ antibody _ catalog: 39123 ; chip _ antibody _ lot: 229 - Characteristics: Homo sapiens\n",
      "TARGET\n",
      "Cell Line: H1 - Cell Type: Embryonic Stem Cell - Tissue Type: Embryo - Factor: H2BK5ac <end>\n",
      "PREDICTED\n",
      "cell line: h1 - cell type: embryonic stem cell - tissue type: embryo - factor: h2bk5ac <end>\n",
      "Training complete, now testing...\n",
      "Epoch 10 Training Loss 0.1910, Test Loss 0.2386\n",
      "Title: H3K27me3 _ human1 _ rep1 - Description: individual: 1 ; cell type: Cranial neural crest cells ( CNCCs ) ; cnccs derived from: H9 ( ESC ) ; chip antibody: anti - H3K27me3 ( Active Motif, catalog# 39536, lot# 09508002 )  - Characteristics: Homo sapiens\n",
      "TARGET\n",
      "Cell Line: None - Cell Type: Neural crest cell - Tissue Type: Cranial - Factor: H3K27me3 <end>\n",
      "PREDICTED\n",
      "cell line: none - cell type: neural stem cell - tissue type: none - factor: h3k27me3 <end>\n",
      "Training complete, now testing...\n",
      "Epoch 11 Training Loss 0.1544, Test Loss 0.2135\n",
      "Title: ChIP - seq _ RS _ H3K9me2 _ 1 - Description: genotype: Wild - type ; strain: C57BL/6 ; cell type: Isolated round spermatids ; chip antibody: Mouse anti - H3K9me2 ( Abcam: ab1220 )  - Characteristics: Mus musculus\n",
      "TARGET\n",
      "Cell Line: None - Cell Type: Spermatid - Tissue Type: None - Factor: H3K9me2 <end>\n",
      "PREDICTED\n",
      "cell line: none - cell type: inner cell mass - tissue type: none - factor: h3k9me2 <end>\n",
      "Training complete, now testing...\n",
      "Epoch 12 Training Loss 0.1257, Test Loss 0.1959\n",
      "Title: HSC _ K4me3 _ 2 - Description: strain: C57Bl/6J ; chip antibody: H3K4me3 ( Abcam ab8580 ) ; cell type: haematopoietic stem and progenitor cell ( HSC )  - Characteristics: Mus musculus\n",
      "TARGET\n",
      "Cell Line: None - Cell Type: Hematopoietic Stem Cell - Tissue Type: None - Factor: H3K4me3 <end>\n",
      "PREDICTED\n",
      "cell line: none - cell type: hematopoietic stem cell - tissue type: bone marrow - factor: h3k4me3 <end>\n",
      "Training complete, now testing...\n",
      "Epoch 13 Training Loss 0.1038, Test Loss 0.1811\n",
      "Title: ATAC - Seq _ Sample08 _ CEC _ Rep4 - Description: none - Characteristics: cell type: corneal epithelium\n",
      "TARGET\n",
      "Cell Line: None - Cell Type: Epithelium - Tissue Type: Corneal Epithelium - Factor: ATAC-seq <end>\n",
      "PREDICTED\n",
      "cell line: none - cell type: monocyte - tissue type: blood - factor: atac-seq <end>\n",
      "Training complete, now testing...\n",
      "Epoch 14 Training Loss 0.0875, Test Loss 0.1706\n",
      "Title: Brd4 _ shMed23 _ OffDox _ ChIPSeq - Description: strain: C57BL/6 ; cell type: Acute myeloid leukemia ; genotype: MLL - AF9/NrasG12D ; antibody: Brd4 ( A301 - 985A ; Bethyl )  - Characteristics: Mus musculus\n",
      "TARGET\n",
      "Cell Line: None - Cell Type: Acute myeloid leukemia - Tissue Type: None - Factor: BRD4 <end>\n",
      "PREDICTED\n",
      "cell line: none - cell type: acute myeloid leukemia - tissue type: none - factor: brd4 <end>\n",
      "Training complete, now testing...\n",
      "Epoch 15 Training Loss 0.0710, Test Loss 0.1620\n",
      "Title: Blood Donor No.6 _ stimulated PBMCs _ STAT4 ChIP - Seq - Description: PBMCs were stimulated for 2.5 hours either with immune complexes consisting of small nuclear ribonucleoprotein ( snRNP ) particles and IgG from an SLE patient for IRF5, or with 500 U/ml of IFN - α2b for STAT4. - Characteristics: cell type: peripheral blood mononuclear cells ( PBMCs ) ; stimulated with: 500 U/ml of IFN - α2b ; chip antibody: STAT4 ; chip antibody vendor: Santa Cruz Biotechnology ; chip antibody cat. #: sc - 486 ; chip antibody lot #: K1108\n",
      "TARGET\n",
      "Cell Line: None - Cell Type: Monocyte - Tissue Type: Blood - Factor: STAT4 <end>\n",
      "PREDICTED\n",
      "cell line: none - tissue type: spleen - factor: t <end>\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "in_vocab_size = len(tokenizer.word_index) + 1\n",
    "out_vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "encoder = Encoder(in_vocab_size, EMBEDDING_SIZE, LSTM_SIZE)\n",
    "decoder = Decoder(out_vocab_size, EMBEDDING_SIZE, LSTM_SIZE)  \n",
    "  \n",
    "test_losses = []\n",
    "training_losses = []\n",
    "for e in range(NUM_EPOCHS):\n",
    "    en_initial_states = encoder.init_states(BATCH_SIZE)\n",
    "    training_loss = 0.0\n",
    "    training_samples = 0.0\n",
    "    for batch, (source_seq, target_seq_in, target_seq_out) in enumerate(training_set.take(-1)):\n",
    "        if(len(source_seq)== BATCH_SIZE):\n",
    "            training_loss += train_step(source_seq, target_seq_in, target_seq_out, en_initial_states)\n",
    "            training_samples += 1\n",
    "        \n",
    "        \n",
    "    print(\"Training complete, now validating...\")\n",
    "    training_loss = training_loss/training_samples\n",
    "    if(e == 0):\n",
    "        old_val_loss == 999\n",
    "    else:\n",
    "        old_val_loss = val_loss\n",
    "    val_loss = 0.0\n",
    "    val_samples = 0.0\n",
    "    for batch, (source_seq, target_seq_in, target_seq_out) in enumerate(val_set.take(-1)):\n",
    "        if(len(source_seq) == BATCH_SIZE):\n",
    "            val_loss += test_step(source_seq, target_seq_in,\n",
    "                                    target_seq_out, en_initial_states)\n",
    "            val_samples += 1\n",
    "        \n",
    "    val_loss = val_loss/val_samples\n",
    "    \n",
    "    print(f\"Old validation loss =  {old_val_loss}, new validation loss = {val_loss}...\")\n",
    "    if(val_loss > old_val_loss):\n",
    "        print(\"Validation loss increased, breaking training...\")\n",
    "        break\n",
    "    print('Epoch {} Training Loss {:.4f}, Val Loss {:.4f}'.format(e + 1, training_loss.numpy(), val_loss.numpy()))\n",
    "    try:\n",
    "        predict()\n",
    "    except Exception:\n",
    "        continue\n",
    "    training_losses.append(training_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1185,
     "status": "ok",
     "timestamp": 1584806409803,
     "user": {
      "displayName": "Giuseppe Cannizzaro",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh2rwxXOtNd1FXyx9Hy22uSBPNBSANIiogcvrnB-w=s64",
      "userId": "07112207170858818112"
     },
     "user_tz": -60
    },
    "id": "4bNroHpsqfE4",
    "outputId": "7e408678-f3d2-453b-bd5f-dc8a5ff6299a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3deXyU9b33/9dnJvsekkBCwg4S9iAR\nWZTFpeJWqNWjaK3e1lp7rHrsfaq23ufo8f55jj2n99FabZVatKfHurZaLajVo4iKCgFRiewQIGHJ\nAmQhe/L5/XFdCQNkGciQSWY+z8djHjNzbfOZiO/rmu/1vb6XqCrGGGNClyfYBRhjjDm9LOiNMSbE\nWdAbY0yIs6A3xpgQZ0FvjDEhLiLYBXQkPT1dhw8fHuwyjDGm31i7dm25qmZ0NK9PBv3w4cMpKCgI\ndhnGGNNviMiuzuZZ040xxoQ4C3pjjAlxFvTGGBPi+mQbfUeampooLi6mvr4+2KWErZiYGHJycoiM\njAx2KcaYk9Bvgr64uJjExESGDx+OiAS7nLCjqlRUVFBcXMyIESOCXY4x5iT0m6ab+vp60tLSLOSD\nRERIS0uzX1TG9EP9JugBC/kgs7+/Mf1Tvwr6rrSqUlpdT3V9U7BLMcaYPiVkgl6AsuoGKusCH/QV\nFRXk5eWRl5dHZmYm2dnZ7e8bGxu7XLegoIA77rij28+YNWtWQGpdsWIFl112WUC2ZYwJDf3mZGx3\nRISYSC/1Ta0B33ZaWhrr168H4IEHHiAhIYF//Md/bJ/f3NxMRETHf8r8/Hzy8/O7/YxVq1YFplhj\njDlOyBzRA8RGeqlvaqE37pp14403cuutt3L22Wdz9913s3r1ambOnMnUqVOZNWsWmzdvBo49wn7g\ngQe46aabmDdvHiNHjuSxxx5r315CQkL78vPmzePKK68kNzeX6667rv37LF++nNzcXKZNm8Ydd9zR\n7ZH7wYMHWbRoEZMnT2bGjBl8+eWXAHzwwQftv0imTp1KdXU1+/btY86cOeTl5TFx4kQ+/PDDgP/N\njDHB0e0RvYgsBS4DSlV1YgfzfwJc57O9cUCGqh4UkSKgGmgBmlW1+0NbP/zLG4V8vbfqhOnNra00\nNLUSF+U96ROH4wcncf/lE05qneLiYlatWoXX66WqqooPP/yQiIgI3n33XX72s5/xpz/96YR1Nm3a\nxPvvv091dTVjx47lhz/84Qn90j///HMKCwsZPHgws2fP5uOPPyY/P58f/OAHrFy5khEjRrB48eJu\n67v//vuZOnUqr732Gu+99x7f/e53Wb9+Pb/4xS944oknmD17NjU1NcTExLBkyRIuuugi7rvvPlpa\nWqitrT2pv4Uxpu/yp+nmWeBx4L86mqmq/wH8B4CIXA7cpaoHfRaZr6rlPazTLx433FsVvL3QQeSq\nq67C6/UCUFlZyQ033MDWrVsREZqaOj5XcOmllxIdHU10dDQDBw7kwIED5OTkHLPM9OnT26fl5eVR\nVFREQkICI0eObO/DvnjxYpYsWdJlfR999FH7zua8886joqKCqqoqZs+ezY9//GOuu+46rrjiCnJy\ncjjrrLO46aabaGpqYtGiReTl5fXob2OM6Tu6DXpVXSkiw/3c3mLg+Z4U5I/OjrxbW5XCvZUMTIph\nUFLM6S6D+Pj49tf/9E//xPz583n11VcpKipi3rx5Ha4THR3d/trr9dLc3HxKy/TEvffey6WXXsry\n5cuZPXs2b7/9NnPmzGHlypUsW7aMG2+8kR//+Md897vfDejnGmOCI2Bt9CISBywAfNsrFPibiKwV\nkVu6Wf8WESkQkYKysrJTqsHjEaIinHb63lZZWUl2djYAzz77bMC3P3bsWHbs2EFRUREAL774Yrfr\nnHvuuTz33HOA0/afnp5OUlIS27dvZ9KkSdxzzz2cddZZbNq0iV27djFo0CC+//3vc/PNN7Nu3bqA\nfwdjTHAE8mTs5cDHxzXbnKOqZwIXA7eJyJzOVlbVJaqar6r5GRkdjp3vl5hID3VBCPq7776bn/70\np0ydOjXgR+AAsbGx/PrXv2bBggVMmzaNxMREkpOTu1zngQceYO3atUyePJl7772X3//+9wA8+uij\nTJw4kcmTJxMZGcnFF1/MihUrmDJlClOnTuXFF1/kzjvvDPh3MMYEh/jTQ8VtuvlrRydjfZZ5FXhZ\nVf/YyfwHgBpV/UV3n5efn6/H33hk48aNjBs3rttaD1TVc6CqngmDk/F6QutKzpqaGhISElBVbrvt\nNsaMGcNdd93VqzX4+9/BGNO7RGRtZx1eAnJELyLJwFzgLz7T4kUkse018A1gQyA+ryuxkc7J0WA0\n35xuv/3tb8nLy2PChAlUVlbygx/8INglGWP6AX+6Vz4PzAPSRaQYuB+IBFDVJ93FvgX8TVWP+Kw6\nCHjV7eYYAfxRVd8KXOkdi4l09l31TS3ER4fM9WAA3HXXXb1+BG+M6f/86XXTbYdtVX0Wpxum77Qd\nwJRTLexURXo9eEWobw78FbLGGNMfhdSVseAzFEJj6DXdGGPMqQi5oAen+aa+uXeGQjDGmL4uRIPe\nS0ur0tRiQW+MMaF1ttIV49PzJiqi5/uyiooKzj//fAD279+P1+ulra//6tWriYqK6nL9FStWEBUV\n1eFQxM8++ywFBQU8/vjjPa7TGGM6EqJBf7TnTVJsz29k3d0wxd1ZsWIFCQkJARtz3hhjTkZINt14\nPR6iIjyntS/92rVrmTt3LtOmTeOiiy5i3759ADz22GOMHz+eyZMnc80111BUVMSTTz7JI488Ql5e\nXpfD/xYVFXHeeecxefJkzj//fHbv3g3Ayy+/zMSJE5kyZQpz5jgXFxcWFjJ9+nTy8vKYPHkyW7du\nPW3f1RjTv/XPI/o374X9X3W5yPCmFlpVIcrPr5g5CS5+2K9FVZXbb7+dv/zlL2RkZPDiiy9y3333\nsXTpUh5++GF27txJdHQ0hw8fJiUlhVtvvdWvXwG33347N9xwAzfccANLly7ljjvu4LXXXuPBBx/k\n7bffJjs7m8OHDwPw5JNPcuedd3LdddfR2NhIS4v1MjLGdKx/Br0fPB6huVlRFCGwQyE0NDSwYcMG\nLrzwQgBaWlrIysoCYPLkyVx33XUsWrSIRYsWndR2P/nkE/785z8DcP3113P33XcDMHv2bG688Ub+\n7u/+jiuuuAKAmTNn8tBDD1FcXMwVV1zBmDFjAvX1jDEhpn8GvR9H3nW1jew6WMvogQnE+XtU7ydV\nZcKECXzyyScnzFu2bBkrV67kjTfe4KGHHuKrr7r+5eGPJ598ks8++4xly5Yxbdo01q5dy7XXXsvZ\nZ5/NsmXLuOSSS3jqqac477zzevxZxpjQE5Jt9ODb8ybwV8hGR0dTVlbWHvRNTU0UFhbS2trKnj17\nmD9/Pj//+c+prKykpqaGxMREqquru93urFmzeOGFFwB47rnnOPfccwHYvn07Z599Ng8++CAZGRns\n2bOHHTt2MHLkSO644w4WLlzYfptAY4w5XsgGfVSEB4/IaTkh6/F4eOWVV7jnnnuYMmUKeXl5rFq1\nipaWFr7zne8wadIkpk6dyh133EFKSgqXX345r776arcnY3/1q1/xzDPPMHnyZP7whz/wy1/+EoCf\n/OQnTJo0iYkTJzJr1iymTJnCSy+9xMSJE8nLy2PDhg12kxBjTKf8Gqa4t/VkmGJf20pr8AiMzEgI\nZHlhzYYpNqZvOu3DFPdVMZFOF8u+uDMzxpjeEuJB76W5VWlutaA3xoSvfhX0J3tkHhPCNyEJBvtl\nZEz/1G+CPiYmhoqKipMKm5iIo0MhmJ5RVSoqKoiJiQl2KcaYk9Rv+tHn5ORQXFxMWVnZSa1XUVlP\n9X4P5fFdDzxmuhcTE0NOTk6wyzDGnKR+E/SRkZGMGDHipNf792dWs6+ynrf+Yc5pqMoYY/q+ftN0\nc6pys5LYXlZDo91a0BgTproNehFZKiKlIrKhk/nzRKRSRNa7j3/2mbdARDaLyDYRuTeQhfsrNzOR\nphZlR3lNMD7eGGOCzp8j+meBBd0s86Gq5rmPBwFExAs8AVwMjAcWi8j4nhR7KsZlJQGwaV/3QxAY\nY0wo6jboVXUlcPAUtj0d2KaqO1S1EXgBWHgK2+mREenxRHk9bNxf1dsfbYwxfUKg2uhnisgXIvKm\niExwp2UDe3yWKXan9apIr4fRAxPsiN4YE7YCEfTrgGGqOgX4FfDaqWxERG4RkQIRKTjZLpTdyc1K\nZJMd0RtjwlSPg15Vq1S1xn29HIgUkXSgBBjis2iOO62z7SxR1XxVzW+78XagjMtM4kBVAwePNAZ0\nu8YY0x/0OOhFJFNExH093d1mBbAGGCMiI0QkCrgGeL2nn3cqcrMSAeyo3hgTlrq9YEpEngfmAeki\nUgzcD0QCqOqTwJXAD0WkGagDrlFnnIJmEfkR8DbgBZaqauFp+RbdyM10et5s3FfNrFHpwSjBGGOC\nptugV9XF3cx/HHi8k3nLgeWnVlrgZCRGk54QzaZ9dkRvjAk/IX9lbJtxWYls2m89b4wx4Sdsgj43\nM5EtB6ppbrGhEIwx4SWMgj6JhuZWiipqg12KMcb0qvAJeut5Y4wJU2ET9KMHJuD1iF0ha4wJO2ET\n9NERXkZlxNsRvTEm7IRN0IPTTr/RjuiNMWEmvII+K5GSw3VU1TcFuxRjjOk1YRX049wrZDdbf3pj\nTBgJq6Bv73ljV8gaY8JIWAV9ZlIMybGRbLQjemNMGAmroBcRcjMT7YjeGBNWwirowbmH7Ob91bS2\narBLMcaYXhF2QZ+bmciRxhaKD9UFuxRjjOkV4Rf0We7Y9HbhlDEmTIRd0I8dlIgINhSCMSZshF3Q\nx0Z5GZFmQyEYY8JH2AU9OP3pN1rPG2NMmAjPoM9MYtfBWo40NAe7FGOMOe3CNOgTUYUtB6yd3hgT\n+roNehFZKiKlIrKhk/nXiciXIvKViKwSkSk+84rc6etFpCCQhffEOLfnjd1D1hgTDvw5on8WWNDF\n/J3AXFWdBPxfYMlx8+erap6q5p9aiYGXnRJLQnSEXSFrjAkLEd0toKorRWR4F/NX+bz9FMjpeVmn\nl8cjjM1MtDFvjDFhIdBt9N8D3vR5r8DfRGStiNzS1YoicouIFIhIQVlZWYDLOlHbmDeqNhSCMSa0\nBSzoRWQ+TtDf4zP5HFU9E7gYuE1E5nS2vqouUdV8Vc3PyMgIVFmdys1Koqq+mX2V9af9s4wxJpgC\nEvQiMhl4GlioqhVt01W1xH0uBV4Fpgfi8wJhXKY7Nr1dOGWMCXE9DnoRGQr8GbheVbf4TI8XkcS2\n18A3gA577gTDGW7Q2z1kjTGhrtuTsSLyPDAPSBeRYuB+IBJAVZ8E/hlIA34tIgDNbg+bQcCr7rQI\n4I+q+tZp+A6nJCkmkpzUWOtiaYwJef70ulnczfybgZs7mL4DmHLiGn1HbmaSdbE0xoS8sLwyts24\nrER2lB+hvqkl2KUYY8xpE9ZBn5uZREursq20JtilGGPMaRPeQZ/V1vPG2umNMaErrIN+eFo8MZEe\na6c3xoS0sA56r0cYOyjRjuiNMSEtrIMe3J43dtGUMSaEWdBnJVJe00hptQ2FYIwJTRb0me7Y9HaF\nrDEmRFnQ25g3xpgQF/ZBnxofRWZSjB3RG2NCVtgHPTjt9HYTEmNMqLKgx2mn31ZaTVNLa7BLMcaY\ngLOgxxnzpqlF2VF2JNilGGNMwFnQ49Pzxk7IGmNCkAU9MDIjnkiv2E1IjDEhyYIeiPR6GD0w0Y7o\njTEhyYLeNS4z0bpYGmNCkgW9Kzcrkf1V9Rw60hjsUowxJqAs6F1HT8jaUb0xJrRY0LuO3oTE2umN\nMaHFr6AXkaUiUioiGzqZLyLymIhsE5EvReRMn3k3iMhW93FDoAoPtIGJMaQnRFk7vTEm5Ph7RP8s\nsKCL+RcDY9zHLcBvAERkAHA/cDYwHbhfRFJPtdjTzcamN8aEIr+CXlVXAge7WGQh8F/q+BRIEZEs\n4CLgHVU9qKqHgHfoeocRVLmZiWw+UE1Lqwa7FGOMCZhAtdFnA3t83he70zqbfgIRuUVECkSkoKys\nLEBlnZzcrCTqm1rZVWFDIRhjQkefORmrqktUNV9V8zMyMoJSw9Gx6a2d3hgTOgIV9CXAEJ/3Oe60\nzqb3SaMHJuD1CBv3WTu9MSZ0BCroXwe+6/a+mQFUquo+4G3gGyKS6p6E/YY7rU+KifQyMj3exrwx\nxoSUCH8WEpHngXlAuogU4/SkiQRQ1SeB5cAlwDagFvhf7ryDIvJ/gTXuph5U1a5O6gZdblYSn+8+\nFOwyjDEmYPwKelVd3M18BW7rZN5SYOnJlxYcuZmJvPHFXqrqm0iKiQx2OcYY02N95mRsXzHOvUJ2\ni52QNcaECAv647SNeWP3kDXGhAoL+uNkJceQFBPBJut5Y4wJERb0xxERcrOSrC+9MSZkWNB3YFxm\nIpv3V9NqQyEYY0KABX0HcrOSqGlopuRwXbBLMcaYHrOg70DbUAh2hawxJhRY0HdgbGYiIjbmjTEm\nNFjQdyAuKoLhafE2Nr0xJiRY0HciNzPR7jZljAkJoRX0xQXQFJgTqLmZSeysOEJdY0tAtmeMMcES\nOkFfexD+axE8fSFUbO/x5nKzElGFLQfsqN4Y07+FTtDHDYBvPw2Ve+CpuVD4ao82N84dCsHa6Y0x\n/V3oBD3A2AVw60cwMBdevhGW/wSaG05pUzmpscRHeW1semNMvxdaQQ+QMgRuXA4zboPVS2DpRXCo\n6KQ34/EIYzMT7YjeGNPvhV7QA0REwYJ/hav/Gyp2wFNzYNOyk95MblYSG/dV4wy3b4wx/VNoBn2b\ncZfDDz6A1BHwwrXw9n3Q0uT/6pmJVNY1sb+q/jQWaYwxp1doBz3AgBHwvb/BWd+HTx6HZy6BymK/\nVs3Nck/IWju9MaYfC/2gB4iIhkt/AVc+A6Ub4clzYMvful1tbNuYN9ZOb4zpx/wKehFZICKbRWSb\niNzbwfxHRGS9+9giIod95rX4zHs9kMWftIlXwC0rICkb/ngVvPsAtDR3unhSTCTZKbF2RG+M6de6\nvTm4iHiBJ4ALgWJgjYi8rqpfty2jqnf5LH87MNVnE3Wqmhe4knsofTTc/C68eQ989AjsWQ3f/h0k\nZXW4+Lgs63ljjOnf/Dminw5sU9UdqtoIvAAs7GL5xcDzgSjutImMhW8+Bt9aAns/d5pytr/X4aK5\nmUlsLztCQ7MNhWCM6Z/8CfpsYI/P+2J32glEZBgwAvBNzRgRKRCRT0VkUWcfIiK3uMsVlJWV+VFW\nAEy52mnKic+AP1wB7/8rtB4b6LlZibS0Ki+s3kN9k4W9Mab/CfTJ2GuAV1TVNxGHqWo+cC3wqIiM\n6mhFVV2iqvmqmp+RkRHgsrqQMRa+/z8wZTF88HP4w7egprR99uxR6YzKiOf+1ws566F3ue/Vr/hi\nz2HrW2+M6Tf8CfoSYIjP+xx3Wkeu4bhmG1UtcZ93ACs4tv2+b4iKh2/9BhY+AXs+c5pydn4IQGp8\nFO/cNZc/fv9sLhg3iFfWFrPwiY9Z8OiHPP3hDsprTm2IBWOM6S3S3ZGpiEQAW4DzcQJ+DXCtqhYe\nt1wu8BYwQt2NikgqUKuqDSKSDnwCLPQ9kduR/Px8LSgoOMWv1EMHCuGlG+Dgdph/H5zzY/Ac3R9W\n1Tfx1y/28VLBHtbvOUyERzh/3ECumjaEeWMziPCGR49VY0zfIiJr3daTE+f50wQhIpcAjwJeYKmq\nPiQiDwIFqvq6u8wDQIyq3uuz3izgKaAV59fDo6r6u+4+L6hBD9BQDW/8A2x4BUZf4Jy0jU87YbGt\nB6p5eW0xf15XTHlNIxmJ0VwxNZur8nMYPTAxCIUbY8JVj4O+twU96AFUYe0z8Oa9zhDIk/8Ohp0D\nQ2dATNIxiza1tPL+plJeXlvMe5tKaWlVzhyawlX5Q7hschaJMZFB+hLGmHBhQd8T+76At37q9Ldv\nbQLxQNYUGH6OE/zDZkJMcvvipdX1vPZ5CS8XFLO1tIaYSA+XTMziqvwhnD1iAB6PBPHLGGNClQV9\nIDTWQvFqKPoIij6GkgJoaXSCP3MSDD8Xhs12gj82FVVl/Z7DvLy2mDfW76W6oZmhA+K4cloO356W\nQ3ZKbLC/kTEmhFjQnw5NdVC8xgn9oo+c1y0NgEDmRJ/gn0VdRDJvFe7j5YJiVm2vQATOGZ3OFWdm\nc+6YDNITooP9bYwx/ZwFfW9oqneO8os+hqIPneBvrgcEBk1wm3pmU5I8lRe/ruNPa4spOezcyDw3\nM5GZo9KYPSqds0cOsDZ9Y8xJs6APhuYGKFnnHO3v+gh2fwbNTrAzcDw6bDY7U2byVuMkVm0/xJqi\ngzQ0t+L1CJNzkpnlBv+Zw1KJifQG97sYY/o8C/q+oLnRGVen6EPY9bET/E1HIGMczLuH+jGXsW5P\nJau2VbBqezlfFFfS0qpER3jIH57KrFHpzBqVxqTsZOurb4w5gQV9X9TSBF//BT74dyjf3B74jFsI\nHg/V9U2s3nmQVdsr+HhbOZv2O0MlJ0ZHcPbINGaPTmPWqHTOGJSAiPXkMSbcWdD3Za0tUPjq0cAf\nOB7m3gPjvnnMFbnlNQ18st052l+1vYJdFbUApCdEO808bvAPGRAXrG9ijAkiC/r+oD3wfw7lWzoN\n/DbFh2pZta2Cj93gL6t2xtwZMiCWb5+Zw23zRxNpTTzGhA0L+v7khMCf4DTp5F7eYeADqCrbSmv4\neFs5K7aUsWJzGfnDUvnVtVPJSrb++saEAwv6/ugUAr/NX9aX8LM/f0VUhIf/vDqP+WMH9lLRxphg\n6Sro7bd9X+XxwqQr4e8/hSuedq7Cfem7zhDKX/8FWls7XXVhXjav334Og5Ji+F/PrOHnb22iuaXz\n5Y0xoc2Cvq/zeGHyVXDbZ8cG/lPnwtevdxr4ozISeO222SyePpTfrNjO4t9+yr7Kul4u3hjTF1jQ\n9xfHB35zA7x0fZeBHxPp5d+umMQvr8nj671VXPrYR6zYXNrBxo0xocyCvr85JvB/6wyz0E3gtzXl\nDEyM5sZn1vDv1pRjTFixoO+vPF5njPzbVh8X+HNg81snLO7blPNra8oxJqxY0Pd3bYH/9585d8Jq\nqoXnr4bnr4XDe45ZtK0p59Gr8yi0phxjwoYFfajwRsCUq50mnQv+Bba/B0+cDat+BS3Nxyy6aGo2\nb1hTjjFhw4I+1Hgj4Zx/cAJ/xLnwt/8DS+bBnjXHLHa0KWdIe1PO/sr64NRsjDmtLOhDVeowWPwC\nXP3fUFsBv7vQueF53aH2RZymnMntTTmXPPahNeUYE4L8CnoRWSAim0Vkm4jc28H8G0WkTETWu4+b\nfebdICJb3ccNgSzedEMExl0OP1oNM/4e1v0eHj8LvnzJufm5a9HUbF7/0TlkJDhNOf/xtjXlGBNK\nuh0CQUS8wBbgQqAYWAMsVtWvfZa5EchX1R8dt+4AoADIBxRYC0xT1UN0wYZAOE32fQF/vQtK1sKI\nuXDpf0L66PbZdY0t/MsbhbywZg/Thw/gscVTyUyOCWLBxhh/9XQIhOnANlXdoaqNwAvAQj8/+yLg\nHVU96Ib7O8ACP9c1gZY1Bb73Dlz6/2DvevjNTFjxsHMbRCA2ysvD357MI1dPYcPeSi557EM+2FIW\n5KKNMT3lT9BnA7799Irdacf7toh8KSKviMiQk1wXEblFRApEpKCszMLltPF44ayb4UdrnCGQV/wb\n/GYW7FjRvsi3pua0N+XcsHS1NeUY088F6mTsG8BwVZ2Mc9T++5PdgKouUdV8Vc3PyMgIUFmmU4mD\n4MrfwfWvAgr/tRD+9H2ocU7Gjh7o9Mq55qwhPPH+dq797WfsqjgS3JqNMafEn6AvAYb4vM9xp7VT\n1QpVbXDfPg1M83ddE2SjzoMffuLc5OTr1+DxfChYCq2tJzTlzP/FCu584XM27a8KdtXGmJPgz8nY\nCJyTsefjhPQa4FpVLfRZJktV97mvvwXco6oz3JOxa4Ez3UXX4ZyMPdjVZ9rJ2CAp3+qcrC36EHLO\ngssegcxJAJRW1fO7j3by35/u4khjCxeMG8jfzx/NmUNTg1y0MQYCcOMREbkEeBTwAktV9SEReRAo\nUNXXReTfgG8CzcBB4Iequsld9ybgZ+6mHlLVZ7r7PAv6IFJ1ul++/TOnz/2MH8K8n0J0AgCHaxv5\n/apdPLNqJ4drm5gxcgC3zR/NOaPT7SblxgSR3WHKnLzag/A//wJrn4WkHLjk3yH30vbZRxqaeX71\nbp7+cCf7q+qZlJ3MbfNH8Y3xmXg8FvjG9DYLenPqdn/mNOeUFkLGOMi9xAn8rKng8dDQ3MKr60p4\n8oPtFFXUMnpgArfOHcXCvMF2c3JjepEFvemZlibnqtoNr8LuVaCtkJgFYy+GsZfCiHNp8USx/Kt9\nPPH+NjbtryY7JZZb5ozk6rOGEBPpDfY3MCbkWdCbwKk9CFvehs3LYNt70HQEohJh9PmQeyk6+kJW\n7G7iife3UbDrEOkJUdx0zgi+M2MYSTGRwa7emJBlQW9Oj6Z62PkBbFoGm9+EI6XgiYBhs2DspayP\nn8Uja+r5YEsZidERXD9zGDedM4L0hOhgV25MyLGgN6dfa6szhs7mZbBpOZRvdqYPmkRp9nksLRvP\nU9sSiPJ6ueasIXx/zkhyUuOCW7MxIcSC3vS+iu3ukf5y2P0poDQlDGZ11AyeOpDLah3HZVOHcevc\nUYwemBDsao3p9yzoTXAdKYctbzlH+tvfg+Y66r0JvNs0mbebz6Rm8CxmTxnHJZOyGJwSG+xqjemX\nLOhN39FY6wygtnkZrZvewlNXDsCW1mw+bR3PgQH5DJ5yAeflTyAr2ULfGH9Z0Ju+qbUFStZB0YfU\nbl1JRMlnRLXUArC1NZsd8VOIGjWXCbMuYeDgoUEu1pi+zYLe9A8tTbDvCyoK36N60/sMPPQ5cdQB\nUOLNoTpzBplTLiBl3HxIzAxyscb0LRb0pn9qaaZk46cUrX2byD2rGNdUSKI4wV8ZN4zIUXOIGzMX\nhs+GpMFBLtaY4LKgNyFh+4HDFHzyAVWb3mfkkfWc5dlEkhv8zSkjiRh5Dgw/F4bNhuQO729jTMiy\noDchZ1tpDW9+Wczm9avIPGOWDIYAABC4SURBVFTADM9GZkZsJl7dm6OkDIXMye5jkvNIznFumG5M\nCLKgNyFtW2kNy7/ax5tfFOMpK2SGdyMXxBcxzrOb5Lo9CO6/8ZgUN/R9wj9jLHhtaAbT/1nQm7Cx\nrbSaZV/u552N+9lQUkU8dZwVt49L0ivIjylmSOM2Iss3QrNzQ3S8UZCRezT4MyfBoIkQmxLcL2LM\nSbKgN2GpvKaBj7aWs3JLGSu3llNe49ztcvygOBYNrWNu0n5Gte4konQD7P8KjvjclL696cdnB5A8\nxJp+TJ9lQW/CXmursnF/FSu3OMFfsOsgTS1KbKSXGSMHMOeMDM7LVoY2bUf2f+UE//6voGIbtDf9\nJMPACU5zT/sj1xmy2XYAJsgs6I05zpGGZj7dUdF+tL+z3DmJm5May5wzMpgzJoNZo9NI8jRC6UbY\n/yXs+xLKNjmPukNHNxadBOlnOKGf0fY8FpKHgsduvmJ6hwW9Md3YXVHLB1vLWLmljE+2V1DT0IzX\nI5w5NIU5YzKYc0YGk7KTndskqjrj97SFfvkW9/VmqDlwdKMRsZA+5mjwt/0CSB0B3ojgfVkTkgJx\nc/AFwC9xbg7+tKo+fNz8HwM349wcvAy4SVV3ufNagK/cRXer6je7+zwLehNMTS2trNt1iJVby1i5\npZyvSioBSI2LZOaoNKYNG8C0YalMGJx04u0S6w5BmU/wl292niv3HF3GEwlpo48Gf8YZzi+CAaMg\nyoZuNqemR0EvIl5gC3AhUAysARar6tc+y8wHPlPVWhH5ITBPVa9259Wo6kmNQ2tBb/qSipoGPtpW\nzgdbyvhsx0FKDjsXacVEepiSk8K0YankD0/lzKGppMRFdbyRhhr3yH/zsTuBgztpPwcAzgnftNHO\nI33M0eekHGsGMl3qadDPBB5Q1Yvc9z8FUNV/62T5qcDjqjrbfW9Bb0LK/sp61u46RMGug6zbdYjC\nvVU0tzr/H40emED+sFSmuY8R6fFIVydqm+qcE77lW32et0L5NmisPrpcRCykjTpuJzAG0kc7J4lN\n2Otp0F8JLFDVm9331wNnq+qPOln+cWC/qv5/7vtmYD1Os87DqvpaJ+vdAtwCMHTo0Gm7du3y57sZ\nE3R1jS2s33OYdbsPUVB0kLW7DlFV3wxAWnwUZ7qhnz8slYnZyf7dLF0Vakrd0N967M7gUBFoy9Fl\n4we6wT/KDX93J5A6zC4GCyNdBX1AzwiJyHeAfGCuz+RhqloiIiOB90TkK1Xdfvy6qroEWALOEX0g\n6zLmdIqN8jJzVBozR6UBTlfO7WU1FOw6REHRIdbtPsQ7XzsnaaO8HiZmJ5E/fABnDnV2ABmJHdxD\nVwQSBzmP4eccO6+50Qn79p2A+wtg03KoLT+6nCfCGfYhdfixj5RhznNsqnULDRP+BH0JMMTnfY47\n7RgicgFwHzBXVRvapqtqifu8Q0RWAFOBE4LemFDh8QhjBiUyZlAii6c74+iX1zSwdtch1u06RMGu\nQzz7cRFLVu4AYHhaHJNzUpiYncSEwclMGJzUeVs/QESU243zjBPn1R50buNY0Xb0v8vZKWz867E7\nAYDoZOeov30n0PZ6hHOuIKKLGky/4k/TTQTOydjzcQJ+DXCtqhb6LDMVeAWniWerz/RUoFZVG0Qk\nHfgEWOh7Ircj1kZvQl19UwuFeyspKDrE2l2H2FBSyd7K+vb5OamxTBycfDT8s5MYmBjTsw9tqD4a\n/Ifd5/bHLmhpOLqseCAp++gOIGW4zy+CIRCXbl1E+5hAdK+8BHgUp3vlUlV9SEQeBApU9XUReReY\nBOxzV9mtqt8UkVnAU0Ar4AEeVdXfdfd5FvQmHB080kjh3ko2lFSxYW8lX++tar+QC2BgYjQTs5OZ\nODiJ8e5OIDsltuuTvf5qbYWa/Ud3BL6Pw7uget9xKwjEp0PCIIjPcJ4TBroP93W8+zo21XoM9QK7\nYMqYfqq6vomv91axYW8VhSWVFO6tYmtpNW4nH1LiIpnoHvFPGOzsBIanxTsXdgVSUx0c3u0G/25n\nXKCaUvdxAI64r5vrT1zXE+HuDNzgj/fdIbTtJAZBXJozwqjtFE6JBb0xIaSusYVN+48N/837q2ls\naQUgPsrLhMHJjB+cxMRsp81/9MCEEy/uCjRVaKg6dgdQU+ruBA74TCtzprU2n7gN8UDsACf049Ig\nboD7SDvxEZvq7hyS7aQyFvTGhLzG5la2llZTWFLlNP/sreLrvVXUNTndMKMiPORmJjLBbfaZMDiJ\ncZlJxEb50dXzdGhtda4i9t0JHCmH2oqjj7pDx77vaMcAzi+GY3YOqT47gwHOjiAmCaITnXGJohOP\nPqISQmYnYUFvTBhqaVV2lh+hcK9z1N/W/l9Z1wSAR2BURgIT3CP/8YOTmJCVTHJcH+x73/ZrobbC\n6Vl0zLPvw51Wd9B57Xu9QYfkxPCP8X3fxeuoeGfIiqgEiIyDyNig7jQs6I0xAKgqJYfrnOAvadsB\nVLG/6mjb+pABsUzIco76J2QnMXFwMgOTetjjJxhaW6GhEuqrnB5H7Y+q456Pn+7zqK+CpiPdfxYA\n4oR+VJy7E4iHyPijr30fnU2PToLsM0/p6/baBVPGmL5NRMhJjSMnNY6LJmS2Ty+vaWg/6m9r/nmr\ncH/7/PSEaPfIP4lxWUmMTE9gRHp88Jp+/OHxOO34sak9205ry4k7gIYqaDwCTbXOc2MNNPq89p1e\nXwlVe93ljzjPHZ20BudE9U+2djyvByzojTGkJ0Qz94wM5p6R0T6tur6Jjfuq2VBytOnno23ltLQe\nbQUYnBzDiIx4RqYnMDIjnhHp8YzKSGBwSizeQPf8CRaP17m1ZCBvL9na4u4I2nYWNc5rbQ3cZ/iw\noDfGdCgxJpLpIwYwfcSA9mn1TS1sL6thZ/kRdpQdcZ9reO3zEqobjp4sjYrwMDwtzjnyz4hnZHo8\nI90dQmq8XXGLx+ucC4hJ6pWPs6A3xvgtJtLrDtNw7IiZqkp5TSM72nYC7o5gS2k172480D66Jzjj\n+o9Ij2dkRoL7C8B5PXRAnH8DvpmTZkFvjOkxESEjMZqMxGjOHpl2zLymllaKD9W17wS2lzm/AlZu\nKeOVtcXHLDsgPoqs5BgGp8Qy2H3OSoklOyWGrORYBiZGE3G6rwcIQRb0xpjTKtLrYUS6035/vOr6\nJorKa9lRXkPxoTpKDtex73Aduytq+XRHBdX1x/ad93qEQYnR7TuAwSkxDE6Odd4nx5CdEktKXGRg\nhoUIIRb0xpigSYyJZFJOMpNyOr55SnV9E/sq690dQD17D9ext7KOvYfr+LL4MG9vqG+/IrhNTKTH\n/UXg7AgyEqNJi48mLSGK9ATnOS0+mtS4yLD5dWBBb4zpsxJjIkmMieSMQYkdzm9tVSqONLL3cB37\nKusoOVzPvvadQT0rNpdRcaTxmJ5CbUQgNS6KtPio9vD3fU5PiCItIdqdH01STES//aVgQW+M6bc8\nnqPnBqYM6bj7Y2urUlXfRHlNIxU1DVQccZ7LaxqpONJARU0jFTWNbNxfRUVNY/uVw8eL9MrRnUFC\nNOnuDsL5leDuHNrnRxEd0XdOLFvQG2NCmscjpMRFkRIXxeiB3d++urG5lUO1jZTXuDsBd2fgu6Mo\nr2lge2kN5TUNNDR33Pc9MSbC2QnE+zQZJUST3rZziD/6Pjn29J5XsKA3xhgfUREeBiXFMMiPYR9U\nlSONLUd/IRz3i6FtZ7GjvIY1RY0crG2ko1FnIjxCWkIUQwfE8fKtswL+nSzojTHmFIkICdERJERH\nMCztxF5Fx2tuaeVQbZPPr4Rjn0/XQb0FvTHG9JIIr6f9nEJvCo++RcYYE8Ys6I0xJsRZ0BtjTIjz\nK+hFZIGIbBaRbSJybwfzo0XkRXf+ZyIy3GfeT93pm0XkosCVbowxxh/dBr2IeIEngIuB8cBiERl/\n3GLfAw6p6mjgEeDn7rrjgWuACcAC4Nfu9owxxvQSf47opwPbVHWHqjYCLwALj1tmIfB79/UrwPni\n9P5fCLygqg2quhPY5m7PGGNML/En6LOBPT7vi91pHS6jqs1AJZDm57oAiMgtIlIgIgVlZWX+VW+M\nMaZbfeZkrKouUdV8Vc3PyMjofgVjjDF+8eeCqRJgiM/7HHdaR8sUi0gEkAxU+LnuCdauXVsuIrv8\nqK0j6UD5Ka7b2/pTrdC/6u1PtUL/qrc/1Qr9q96e1Dqssxn+BP0aYIyIjMAJ6WuAa49b5nXgBuAT\n4ErgPVVVEXkd+KOI/CcwGBgDrO7uA1X1lA/pRaRAVfNPdf3e1J9qhf5Vb3+qFfpXvf2pVuhf9Z6u\nWrsNelVtFpEfAW8DXmCpqhaKyINAgaq+DvwO+IOIbAMO4uwMcJd7CfgaaAZuU9WWQH8JY4wxnfNr\nrBtVXQ4sP27aP/u8rgeu6mTdh4CHelCjMcaYHugzJ2MDaEmwCzgJ/alW6F/19qdaoX/V259qhf5V\n72mpVbSjwZGNMcaEjFA8ojfGGOPDgt4YY0JcyAR9dwOv9SUiMkRE3heRr0WkUETuDHZN3RERr4h8\nLiJ/DXYt3RGRFBF5RUQ2ichGEZkZ7Jo6IyJ3uf8GNojI8yLS/f3repGILBWRUhHZ4DNtgIi8IyJb\n3efUYNbYppNa/8P9d/CliLwqIh3fQTwIOqrXZ97/FhEVkfRAfFZIBL2fA6/1Jc3A/1bV8cAM4LY+\nXi/AncDGYBfhp18Cb6lqLjCFPlq3iGQDdwD5qjoRp/vyNcGt6gTP4gxI6Ote4H9UdQzwP+77vuBZ\nTqz1HWCiqk4GtgA/7e2iuvAsJ9aLiAwBvgHsDtQHhUTQ49/Aa32Gqu5T1XXu62qcIOpwDKC+QERy\ngEuBp4NdS3dEJBmYg3NtB6raqKqHg1tVlyKAWPeK8jhgb5DrOYaqrsS5NsaX7yCGvwcW9WpRneio\nVlX9mzv+FsCnOFfn9wmd/G3BGQH4biBgPWVCJej9Hjytr3HH7p8KfBbcSrr0KM4/vNZgF+KHEUAZ\n8Izb1PS0iHR/1+YgUNUS4Bc4R277gEpV/Vtwq/LLIFXd577eDwwKZjEn4SbgzWAX0RURWQiUqOoX\ngdxuqAR9vyQiCcCfgH9Q1apg19MREbkMKFXVtcGuxU8RwJnAb1R1KnCEvtO0cAy3bXshzs5pMBAv\nIt8JblUnR53+2X2+j7aI3IfTZPpcsGvpjIjEAT8D/rm7ZU9WqAT9KQ2eFkwiEokT8s+p6p+DXU8X\nZgPfFJEinCax80Tkv4NbUpeKgWJVbfuF9ApO8PdFFwA7VbVMVZuAPwOzglyTPw6ISBaA+1wa5Hq6\nJCI3ApcB12nfvnBoFM5O/wv3/7ccYJ2IZPZ0w6ES9O0Dr4lIFM4JrdeDXFOn3Juy/A7YqKr/Gex6\nuqKqP1XVHFUdjvN3fU9V++xRp6ruB/aIyFh30vk4Yy31RbuBGSIS5/6bOJ8+euL4OG2DGOI+/yWI\ntXRJRBbgNDt+U1Vrg11PV1T1K1UdqKrD3f/fioEz3X/TPRISQe+ebGkbeG0j8JKqFga3qi7NBq7H\nOTpe7z4uCXZRIeR24DkR+RLIA/41yPV0yP3V8QqwDvgK5//HPnW5vog8jzMq7VgRKRaR7wEPAxeK\nyFacXyUPB7PGNp3U+jiQCLzj/n/2ZFCL9NFJvafns/r2LxljjDE9FRJH9MYYYzpnQW+MMSHOgt4Y\nY0KcBb0xxoQ4C3pjjAlxFvTGGBPiLOiNMSbE/f9R+Ki4WzN0IgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.arange(NUM_EPOCHS)\n",
    "plt.plot(x, training_losses)\n",
    "plt.plot(x, val_losses)\n",
    "plt.legend([\"Training loss\", \"Val loss\"], loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1008551,
     "status": "ok",
     "timestamp": 1584807435727,
     "user": {
      "displayName": "Giuseppe Cannizzaro",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh2rwxXOtNd1FXyx9Hy22uSBPNBSANIiogcvrnB-w=s64",
      "userId": "07112207170858818112"
     },
     "user_tz": -60
    },
    "id": "oHQtdgrK686A",
    "outputId": "5680b524-0af0-4bd6-e46c-e624623b164f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Target</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title: UACC812.H3K9ac.rep1 - Description: cell...</td>\n",
       "      <td>Cell Line: UACC812 - Cell Type: None - Tissue ...</td>\n",
       "      <td>cell line: v481 - cell type: stem cell - tissu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title: 786O _ H3K27ac _ 2 - Description: cell ...</td>\n",
       "      <td>Cell Line: 786-O - Cell Type: Epithelium - Tis...</td>\n",
       "      <td>cell line: 786-o - cell type: epithelium - tis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Title: K562 _ H4K20me1 _ rep1 - Description: c...</td>\n",
       "      <td>Cell Line: K562 - Cell Type: Erythroblast - Ti...</td>\n",
       "      <td>cell line: k562 - cell type: erythroblast - ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Title: Anti - PolII - S5 - Description: strain...</td>\n",
       "      <td>Cell Line: None - Cell Type: T Lymphocyte - Ti...</td>\n",
       "      <td>cell line: none - cell type: monocyte - tissue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Title: p300S4KO _ 2 - Description: strain: C57...</td>\n",
       "      <td>Cell Line: None - Cell Type: T Lymphocyte - Ti...</td>\n",
       "      <td>cell line: none - cell type: t lymphocyte - ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8509</th>\n",
       "      <td>Title: miwi2KO _ GermCellsTestis _ MACS _ H3K9...</td>\n",
       "      <td>Cell Line: None - Cell Type: Germ Cell - Tissu...</td>\n",
       "      <td>cell line: none - cell type: germ cell - tissu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8510</th>\n",
       "      <td>Title: BJ1 ZFP57 - Description: strain: BJ1 ; ...</td>\n",
       "      <td>Cell Line: None - Cell Type: Embryonic Stem Ce...</td>\n",
       "      <td>cell line: none - cell type: embryonic stem ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>Title: ChIPSeq _ Wap - delE3 _ L1 _ H3K27ac _ ...</td>\n",
       "      <td>Cell Line: None - Cell Type: None - Tissue Typ...</td>\n",
       "      <td>cell line: none - tissue type: bone marrow - f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>Title: ChIP:TASOR _ Cell:MORC2 - KO _ rep1 - D...</td>\n",
       "      <td>Cell Line: K562 - Cell Type: Leukemia - Tissue...</td>\n",
       "      <td>cell line: k562 - cell type: leukemia - tissue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>Title: H3K4me1 _ HFD4 - Description: cell type...</td>\n",
       "      <td>Cell Line: None - Cell Type: Spermatid - Tissu...</td>\n",
       "      <td>cell line: none - cell type: t lymphocyte - ti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8514 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  ...                                          Predicted\n",
       "0     Title: UACC812.H3K9ac.rep1 - Description: cell...  ...  cell line: v481 - cell type: stem cell - tissu...\n",
       "1     Title: 786O _ H3K27ac _ 2 - Description: cell ...  ...  cell line: 786-o - cell type: epithelium - tis...\n",
       "2     Title: K562 _ H4K20me1 _ rep1 - Description: c...  ...  cell line: k562 - cell type: erythroblast - ti...\n",
       "3     Title: Anti - PolII - S5 - Description: strain...  ...  cell line: none - cell type: monocyte - tissue...\n",
       "4     Title: p300S4KO _ 2 - Description: strain: C57...  ...  cell line: none - cell type: t lymphocyte - ti...\n",
       "...                                                 ...  ...                                                ...\n",
       "8509  Title: miwi2KO _ GermCellsTestis _ MACS _ H3K9...  ...  cell line: none - cell type: germ cell - tissu...\n",
       "8510  Title: BJ1 ZFP57 - Description: strain: BJ1 ; ...  ...  cell line: none - cell type: embryonic stem ce...\n",
       "8511  Title: ChIPSeq _ Wap - delE3 _ L1 _ H3K27ac _ ...  ...  cell line: none - tissue type: bone marrow - f...\n",
       "8512  Title: ChIP:TASOR _ Cell:MORC2 - KO _ rep1 - D...  ...  cell line: k562 - cell type: leukemia - tissue...\n",
       "8513  Title: H3K4me1 _ HFD4 - Description: cell type...  ...  cell line: none - cell type: t lymphocyte - ti...\n",
       "\n",
       "[8514 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for index in range(len(test)):\n",
    "    \n",
    "    choice = index\n",
    "    test_source_text = test[choice][0]\n",
    "    target_text = test[choice][2]\n",
    "    test_source_seq = tokenizer.texts_to_sequences([test_source_text])\n",
    "\n",
    "    en_initial_states = encoder.init_states(1)\n",
    "    en_outputs = encoder(tf.constant(test_source_seq), en_initial_states)\n",
    "    \n",
    "    de_input = tf.constant([[tokenizer.word_index['<start>']]])\n",
    "      \n",
    "    de_state_h, de_state_c = en_outputs[1:]\n",
    "    out_words = []\n",
    "    alignments = []\n",
    "\n",
    "    while True:\n",
    "        de_output, de_state_h, de_state_c, alignment = decoder(\n",
    "            de_input, (de_state_h, de_state_c), en_outputs[0])\n",
    "        de_input = tf.expand_dims(tf.argmax(de_output, -1), 0)\n",
    "        out_words.append(tokenizer.index_word[de_input.numpy()[0][0]])\n",
    "        alignments.append(alignment.numpy())\n",
    "        \n",
    "        if out_words[-1] == '<end>' or len(out_words) >= 100:\n",
    "              break\n",
    "\n",
    "    results.append([test_source_text,target_text, ' '.join(out_words)])\n",
    "\n",
    "\n",
    "dataframe_results = pd.DataFrame(results, columns = [\"Text\",\"Target\", \"Predicted\"])\n",
    "# if(SAVE):\n",
    "#     dataframe_results.to_csv(f\"Experiment_2/Results/LSTM_results_{NUM_EPOCHS}epochs.csv\")\n",
    "dataframe_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5uzirmb4_i2"
   },
   "outputs": [],
   "source": [
    "dataframe_results.to_csv(f\"Results/LSTM_{e}epochs.csv\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNwjqX563Lkg2GOGMNw9Fcv",
   "collapsed_sections": [],
   "name": "Encoder-decoder_exp1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
